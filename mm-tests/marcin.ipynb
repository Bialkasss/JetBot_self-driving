{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9cdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import tf2onnx\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    GlobalAveragePooling2D,\n",
    "    Conv2DTranspose,\n",
    "    concatenate,\n",
    "    SeparableConv2D,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    load_img,\n",
    "    img_to_array,\n",
    "    ImageDataGenerator,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Generator\n",
    "\n",
    "import random\n",
    "\n",
    "random_state = 44\n",
    "random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55f8572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_data(data_frame, window_size=3):\n",
    "\n",
    "    window = 2 * window_size + 1  \n",
    "    return data_frame.rolling(window=window, min_periods=1, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37edca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_paths) -> Generator[np.array, float, float]:\n",
    "    for csv_path in csv_paths:\n",
    "        csv_data = pd.read_csv(csv_path, header=None)\n",
    "        csv_data.columns = [\"id\", \"forward\", \"left\"]\n",
    "        \n",
    "        csv_data = smooth_data(csv_data)\n",
    "        \n",
    "        image_paths = glob(f\"{csv_path.removesuffix('.csv')}/*.jpg\")\n",
    "        random.shuffle(image_paths)\n",
    "        \n",
    "        for image_path in image_paths:\n",
    "            image_data = load_img(image_path)\n",
    "            image_number = int(Path(image_path).name.removesuffix(\".jpg\"))\n",
    "            row = csv_data[csv_data[\"id\"]==image_number]\n",
    "            if row.empty:\n",
    "                continue\n",
    "            yield image_data, row[\"forward\"].values[0], row[\"left\"].values[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "76b65284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_preprocess(paths, image_size, batch_size):\n",
    "    def preprocess(image, image_size):\n",
    "        image = img_to_array(image).astype(np.uint8)\n",
    "        \n",
    "        image = cv2.resize(image, (image_size, image_size))\n",
    "        \n",
    "        img_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(10, 10))\n",
    "        \n",
    "        y,u,v = cv2.split(img_yuv)\n",
    "        y_clahe = clahe.apply(y)\n",
    "        img_clahe = cv2.merge((y_clahe, u, v))\n",
    "        img_blurred = cv2.GaussianBlur(img_clahe, (3, 3), 0)\n",
    "        \n",
    "        return img_blurred\n",
    "    \n",
    "    def augment(image, forward, left):\n",
    "        image_flip = cv2.flip(image, 1)  \n",
    "        left_flipped = -left\n",
    "        forward_flipped = forward\n",
    "        return image_flip, forward_flipped, left_flipped\n",
    "\n",
    "    data_loader = load_data(paths)\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "\n",
    "    for image, forward, left in data_loader:\n",
    "\n",
    "        image = preprocess(image, image_size)\n",
    "        image_flipped, forward_flipped, left_flipped = augment(image, forward, left)\n",
    "        \n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image_flipped = image_flipped.astype(np.float32) / 255.0\n",
    "        \n",
    "        batch_images.append(image_flipped)\n",
    "        batch_labels.append([forward_flipped, left_flipped])\n",
    "    \n",
    "        batch_images.append(image)\n",
    "        batch_labels.append([forward, left])\n",
    "\n",
    "        if len(batch_images) == 2 * batch_size:\n",
    "            yield np.array(batch_images), np.array(batch_labels)\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "            \n",
    "    if batch_images:\n",
    "        yield np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d8e41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_wrapper(paths):\n",
    "    for batch_images, batch_labels in load_data_preprocess(paths, 64, 32):\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "43318ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = glob(\"../dataset/*.csv\")\n",
    "random.shuffle(csv_paths)\n",
    "\n",
    "\n",
    "test_paths = csv_paths[:3]\n",
    "train_val_paths = csv_paths[3:]\n",
    "\n",
    "val_path = train_val_paths[0]        \n",
    "train_paths = train_val_paths[1:] \n",
    "\n",
    "img_size = 64\n",
    "batch_size = 16\n",
    "\n",
    "test_loader = load_data_preprocess(test_paths, img_size, batch_size)\n",
    "train_loader = load_data_preprocess(train_paths, img_size, batch_size)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generator_wrapper(train_paths),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 64, 64, 3], [None, 2])\n",
    ").repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generator_wrapper([val_path]),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 64, 64, 3], [None, 2])\n",
    ").repeat()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generator_wrapper(test_paths),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 64, 64, 3], [None, 2])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "12856913",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_samples = sum(\n",
    "    [sum(1 for _ in load_data_preprocess([path], 64, batch_size)) * batch_size * 2 for path in train_paths]\n",
    ")\n",
    "steps_per_epoch = total_train_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d99e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_val_samples = sum(\n",
    "    [sum(1 for _ in load_data_preprocess([path], 64, batch_size)) * batch_size * 2 for path in [val_path]]\n",
    ")\n",
    "val_steps = total_val_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd77d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_samples = sum(\n",
    "    [sum(1 for _ in load_data_preprocess([path], 64, batch_size)) * batch_size * 2 for path in test_paths]\n",
    ")\n",
    "test_steps = total_test_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c2de78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(forward_weight=3.0, left_weight=7.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        forward_true = y_true[:, 0]\n",
    "        left_true = y_true[:, 1]\n",
    "\n",
    "        forward_pred = y_pred[:, 0]\n",
    "        left_pred = y_pred[:, 1]\n",
    "\n",
    "        forward_mse = tf.reduce_mean(tf.square(forward_true - forward_pred))\n",
    "        left_mse = tf.reduce_mean(tf.square(left_true - left_pred))\n",
    "\n",
    "        return forward_weight * forward_mse + left_weight * left_mse\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9da9987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_size):\n",
    "    inputs = Input(shape=(image_size, image_size, 3))\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\",\n",
    "           kernel_regularizer=l2(1e-4))(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = SeparableConv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n",
    "    x = Dropout(0.5)(x)  \n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(2, activation=\"tanh\")(x)\n",
    "\n",
    "    return Model(inputs = inputs, outputs = outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f0966e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_forward(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true[:, 0] - y_pred[:, 0]))\n",
    "\n",
    "def mse_left(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true[:, 1] - y_pred[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "065ef75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPooli  (None, 32, 32, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " separable_conv2d_18 (Separ  (None, 32, 32, 32)        2656      \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " separable_conv2d_19 (Separ  (None, 16, 16, 64)        2400      \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               524416    \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 539650 (2.06 MB)\n",
      "Trainable params: 539650 (2.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(image_size=img_size)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10ada5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=weighted_mse_loss(forward_weight=3.0, left_weight=7.0),\n",
    "    metrics=['mse', mse_forward, mse_left],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0948c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "598/598 [==============================] - 185s 303ms/step - loss: 1.4485 - mse: 0.1160 - mse_forward: 0.0475 - mse_left: 0.1849 - val_loss: 0.6713 - val_mse: 0.0492 - val_mse_forward: 0.0092 - val_mse_left: 0.0894\n",
      "Epoch 2/20\n",
      "598/598 [==============================] - 149s 249ms/step - loss: 0.5091 - mse: 0.0456 - mse_forward: 0.0374 - mse_left: 0.0536 - val_loss: 0.5304 - val_mse: 0.0388 - val_mse_forward: 0.0088 - val_mse_left: 0.0690\n",
      "Epoch 3/20\n",
      "598/598 [==============================] - 148s 247ms/step - loss: 0.4194 - mse: 0.0385 - mse_forward: 0.0358 - mse_left: 0.0413 - val_loss: 0.5798 - val_mse: 0.0426 - val_mse_forward: 0.0108 - val_mse_left: 0.0743\n",
      "Epoch 4/20\n",
      "598/598 [==============================] - 151s 252ms/step - loss: 0.3726 - mse: 0.0345 - mse_forward: 0.0345 - mse_left: 0.0346 - val_loss: 0.5583 - val_mse: 0.0418 - val_mse_forward: 0.0142 - val_mse_left: 0.0695\n",
      "Epoch 5/20\n",
      "598/598 [==============================] - 148s 248ms/step - loss: 0.3414 - mse: 0.0318 - mse_forward: 0.0335 - mse_left: 0.0299 - val_loss: 0.5962 - val_mse: 0.0436 - val_mse_forward: 0.0117 - val_mse_left: 0.0756\n",
      "Epoch 6/20\n",
      "598/598 [==============================] - 142s 237ms/step - loss: 0.3176 - mse: 0.0296 - mse_forward: 0.0325 - mse_left: 0.0267 - val_loss: 0.5105 - val_mse: 0.0370 - val_mse_forward: 0.0103 - val_mse_left: 0.0637\n",
      "Epoch 7/20\n",
      "598/598 [==============================] - 154s 257ms/step - loss: 0.2982 - mse: 0.0277 - mse_forward: 0.0309 - mse_left: 0.0244 - val_loss: 0.7164 - val_mse: 0.0512 - val_mse_forward: 0.0089 - val_mse_left: 0.0934\n",
      "Epoch 8/20\n",
      "598/598 [==============================] - 128s 214ms/step - loss: 0.2832 - mse: 0.0260 - mse_forward: 0.0293 - mse_left: 0.0227 - val_loss: 0.5832 - val_mse: 0.0426 - val_mse_forward: 0.0126 - val_mse_left: 0.0725\n",
      "Epoch 9/20\n",
      "598/598 [==============================] - 150s 251ms/step - loss: 0.2675 - mse: 0.0243 - mse_forward: 0.0275 - mse_left: 0.0212 - val_loss: 0.6370 - val_mse: 0.0459 - val_mse_forward: 0.0108 - val_mse_left: 0.0811\n",
      "Epoch 10/20\n",
      "598/598 [==============================] - 135s 226ms/step - loss: 0.2540 - mse: 0.0227 - mse_forward: 0.0255 - mse_left: 0.0199 - val_loss: 0.6582 - val_mse: 0.0476 - val_mse_forward: 0.0116 - val_mse_left: 0.0837\n",
      "Epoch 11/20\n",
      "598/598 [==============================] - 131s 220ms/step - loss: 0.2498 - mse: 0.0222 - mse_forward: 0.0249 - mse_left: 0.0195 - val_loss: 0.6669 - val_mse: 0.0478 - val_mse_forward: 0.0103 - val_mse_left: 0.0854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f77f47d9fa0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    \n",
    "    validation_steps=val_steps,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "81c58ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 15:55:11.484584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.485275: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-05-25 15:55:11.486445: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-05-25 15:55:11.489113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.489872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.489991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.492871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.492907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-05-25 15:55:11.493259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.493575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-05-25 15:55:11.791379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.791859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.792195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.792644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.792683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-05-25 15:55:11.792899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.792951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-05-25 15:55:11.803322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.803398: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-05-25 15:55:11.803568: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-05-25 15:55:11.804042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.804137: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.804202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.804540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.804559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-05-25 15:55:11.804682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-25 15:55:11.804717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "spec = (tf.TensorSpec((None, 64, 64, 3), tf.float32, name=\"input\"),)\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ae92431",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models_onnx/model_opset11_yuv_3w_73.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "333b0f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 19s 135ms/step - loss: 0.4524 - mse: 0.0401 - mse_forward: 0.0354 - mse_left: 0.0444\n",
      "Test Results:\n",
      "loss: 0.4524\n",
      "mse: 0.0401\n",
      "mse_forward: 0.0354\n",
      "mse_left: 0.0444\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_loader, return_dict=True)\n",
    "\n",
    "print(\"Test Results:\")\n",
    "for name, value in results.items():\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "44dce5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "2/2 [==============================] - 0s 36ms/step\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 50ms/step\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 51ms/step\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 48ms/step\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 43ms/step\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "2/2 [==============================] - 0s 97ms/step\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "2/2 [==============================] - 0s 57ms/step\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "2/2 [==============================] - 0s 58ms/step\n",
      "2/2 [==============================] - 0s 46ms/step\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 41ms/step\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "2/2 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "2/2 [==============================] - 0s 42ms/step\n",
      "2/2 [==============================] - 0s 78ms/step\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "2/2 [==============================] - 0s 45ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Total MSE: 0.0401\n",
      "MSE Forward: 0.0356\n",
      "MSE Left: 0.0446\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Collect the true labels and predictions\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for batch_x, batch_y in test_dataset.take(test_steps*batch_size):  \n",
    "    preds = model.predict(batch_x)\n",
    "    y_pred_list.append(preds)\n",
    "    y_true_list.append(batch_y.numpy())\n",
    "\n",
    "# Convert lists to arrays\n",
    "y_pred_all = np.vstack(y_pred_list)\n",
    "y_true_all = np.vstack(y_true_list)\n",
    "\n",
    "# Compute total MSE\n",
    "total_mse = mean_squared_error(y_true_all, y_pred_all)\n",
    "\n",
    "# Compute per-output MSE\n",
    "mse_forward = mean_squared_error(y_true_all[:, 0], y_pred_all[:, 0])\n",
    "mse_left = mean_squared_error(y_true_all[:, 1], y_pred_all[:, 1])\n",
    "\n",
    "print(f\"Total MSE: {total_mse:.4f}\")\n",
    "print(f\"MSE Forward: {mse_forward:.4f}\")\n",
    "print(f\"MSE Left: {mse_left:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
