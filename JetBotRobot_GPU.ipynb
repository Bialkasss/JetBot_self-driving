{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2\n",
        "# !pip install https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torch_xla-2.0-cp38-cp38-linux_x86_64.whl\n",
        "# !pip install opencv-python-headless\n",
        "# !cp -r drive/MyDrive/put_jetbot_dataset /content/\n",
        "# Then use: \"/content/put_jetbot_dataset/dataset/\" as root_dir\n",
        "\n"
      ],
      "metadata": {
        "id": "kS9pQRK7yKrE"
      },
      "id": "kS9pQRK7yKrE",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1482dccb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1482dccb",
        "outputId": "00d3a165-3bd3-4384-d670-c0c5dd99f3f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "CUDA available: True\n",
            "Current device: Tesla T4\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model on CUDA? True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 12.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.693222284317017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Val]: 100%|██████████| 36/36 [00:02<00:00, 14.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 - Train loss: 0.223130 - Val loss: 0.126989\n",
            "New best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 12.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.492705583572388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 [Val]: 100%|██████████| 36/36 [00:03<00:00, 11.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100 - Train loss: 0.118270 - Val loss: 0.087482\n",
            "New best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 12.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.141254425048828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 [Val]: 100%|██████████| 36/36 [00:03<00:00,  9.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100 - Train loss: 0.101286 - Val loss: 0.088694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 12.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.525228500366211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 [Val]: 100%|██████████| 36/36 [00:02<00:00, 14.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100 - Train loss: 0.096530 - Val loss: 0.089109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 12.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.63398289680481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 [Val]: 100%|██████████| 36/36 [00:04<00:00,  8.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100 - Train loss: 0.093277 - Val loss: 0.078823\n",
            "New best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 12.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.785963296890259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 [Val]: 100%|██████████| 36/36 [00:02<00:00, 14.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100 - Train loss: 0.089679 - Val loss: 0.082192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 11.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.921893119812012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 [Val]: 100%|██████████| 36/36 [00:03<00:00, 10.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100 - Train loss: 0.087548 - Val loss: 0.090245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 12.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.10886526107788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100 [Val]: 100%|██████████| 36/36 [00:03<00:00, 10.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100 - Train loss: 0.082393 - Val loss: 0.092156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 12.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.576364517211914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100 [Val]: 100%|██████████| 36/36 [00:02<00:00, 13.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100 - Train loss: 0.081343 - Val loss: 0.087645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 12.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.83735203742981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100 [Val]: 100%|██████████| 36/36 [00:02<00:00, 14.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 - Train loss: 0.079168 - Val loss: 0.096133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100 [Train]: 100%|██████████| 166/166 [00:13<00:00, 12.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch time: 13.60526728630066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100 [Val]: 100%|██████████| 36/36 [00:02<00:00, 14.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100 - Train loss: 0.078831 - Val loss: 0.094438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100 [Train]:  57%|█████▋    | 95/166 [00:08<00:05, 13.58it/s]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "\n",
        "# Set device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class ApplyCLAHE:\n",
        "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
        "        self.clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img_np = np.array(img)\n",
        "        img_yuv = cv2.cvtColor(img_np, cv2.COLOR_RGB2YUV)\n",
        "        img_yuv[:, :, 0] = self.clahe.apply(img_yuv[:, :, 0])\n",
        "        img_rgb = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
        "        return Image.fromarray(img_rgb)\n",
        "\n",
        "class JetBotDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "        folders = [name for name in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, name))]\n",
        "        for folder_name in folders:\n",
        "            csv_path = os.path.join(root_dir, f\"{folder_name}.csv\")\n",
        "            folder_path = os.path.join(root_dir, folder_name)\n",
        "            if not os.path.exists(csv_path):\n",
        "                continue\n",
        "            df = pd.read_csv(csv_path, header=None, dtype={0: str, 1: float, 2: float})\n",
        "            df.columns = [\"filename\", \"forward\", \"left\"]\n",
        "            for _, row in df.iterrows():\n",
        "                img_path = os.path.join(folder_path, str(row['filename']).zfill(4) + \".jpg\")\n",
        "                if os.path.exists(img_path):\n",
        "                    self.samples.append((img_path, float(row[\"forward\"]), float(row[\"left\"])))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, forward, left = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        target = torch.tensor([forward, left], dtype=torch.float32)\n",
        "        return image, target\n",
        "\n",
        "def get_transforms(augment=True):\n",
        "    common = [\n",
        "        ApplyCLAHE(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        "    if augment:\n",
        "        return transforms.Compose([\n",
        "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
        "            transforms.RandomRotation(2),\n",
        "            transforms.RandomApply([transforms.GaussianBlur(3)], p=0.5),\n",
        "            *common\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose(common)\n",
        "\n",
        "def create_datasets(root_dir, batch_size=32, train_ratio=0.7, val_ratio=0.15):\n",
        "    dataset = JetBotDataset(root_dir, transform=None)\n",
        "    total = len(dataset)\n",
        "    train_len = int(total * train_ratio)\n",
        "    val_len = int(total * val_ratio)\n",
        "    test_len = total - train_len - val_len\n",
        "    train_ds, val_ds, test_ds = random_split(dataset, [train_len, val_len, test_len])\n",
        "    train_ds.dataset.transform = get_transforms(augment=True)\n",
        "    val_ds.dataset.transform = get_transforms(augment=False)\n",
        "    test_ds.dataset.transform = get_transforms(augment=False)\n",
        "\n",
        "    loader_args = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"pin_memory\": True,\n",
        "        \"num_workers\": 2,  # Try 2–4 depending on Colab capacity\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"train\": DataLoader(train_ds, shuffle=True, **loader_args),\n",
        "        \"val\": DataLoader(val_ds, **loader_args),\n",
        "        \"test\": DataLoader(test_ds, **loader_args)\n",
        "    }\n",
        "\n",
        "\n",
        "class ModifiedNvidiaNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 5, stride=2, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.output = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.avgpool(F.relu(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.output(x)\n",
        "\n",
        "def weighted_mse_loss(pred, target):\n",
        "    weights = torch.tensor([0.3, 1.0], device=pred.device)\n",
        "    return ((pred - target) ** 2 * weights).mean()\n",
        "\n",
        "def train_model(model, loaders, epochs=100):\n",
        "    best_loss = float('inf')\n",
        "    patience = 17\n",
        "    counter = 0\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        start = time.time()\n",
        "        for images, targets in tqdm(loaders[\"train\"], desc=f\"Epoch {epoch+1}/{epochs} [Train]\"):\n",
        "            images, targets = images.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = weighted_mse_loss(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        print(\"Train epoch time:\", time.time() - start)\n",
        "\n",
        "        train_loss /= len(loaders[\"train\"])\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, targets in tqdm(loaders[\"val\"], desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
        "                images, targets = images.to(device), targets.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = weighted_mse_loss(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "        val_loss /= len(loaders[\"val\"])\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.6f} - Val loss: {val_loss:.6f}\")\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            torch.save(model.state_dict(), 'best_model_jetbot.pth')\n",
        "            best_loss = val_loss\n",
        "            counter = 0\n",
        "            print(\"New best model saved.\")\n",
        "        else:\n",
        "            counter += 1\n",
        "\n",
        "    # Plot loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss_curves.png')\n",
        "    plt.show()\n",
        "\n",
        "# Main\n",
        "if __name__ == \"__main__\":\n",
        "      # import torch\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    print(\"Current device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA\")\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    loaders = create_datasets(\"/content/put_jetbot_dataset/dataset/\", batch_size=32)\n",
        "    model = ModifiedNvidiaNetwork().to(device)\n",
        "    print(\"Model on CUDA?\", next(model.parameters()).is_cuda)\n",
        "    train_model(model, loaders, epochs=100)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}